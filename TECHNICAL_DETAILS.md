# ğŸ”§ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### **ì‹œìŠ¤í…œ êµ¬ì„±**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DVC (Version Control)                 â”‚
â”‚  Git (ë©”íƒ€ë°ì´í„°) + DVC (ëŒ€ìš©ëŸ‰ íŒŒì¼)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë°ì´í„°ì…‹       â”‚                    â”‚  ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸   â”‚
â”‚  datasets/     â”‚                    â”‚  *.py           â”‚
â”‚  â””â”€ cache/     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  - analyze      â”‚
â”‚     â”œâ”€ *.cache â”‚  ddoc ìºì‹œ ê¸°ë°˜    â”‚  - detect_drift â”‚
â”‚     â”œâ”€ plots/  â”‚  ì¦ë¶„ ë¶„ì„         â”‚  - params.yaml  â”‚
â”‚     â””â”€ drift/  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â””â”€â–º VSCode DVC Plugin (ì‹œê°í™”)
```

---

## ğŸ’¾ ë°ì´í„° êµ¬ì¡°

### **cache ë””ë ‰í† ë¦¬ ìƒì„¸**

```
datasets/test_data/cache/
â”œâ”€â”€ analysis_attribute_analysis_test_data.cache
â”‚   â””â”€â”€ { "file.jpg": { "size": 1.5, "width": 1920, "height": 1080,
â”‚                        "noise_level": 12.3, "sharpness": 67.8, ... } }
â”‚
â”œâ”€â”€ analysis_embedding_analysis_test_data.cache
â”‚   â””â”€â”€ { "file.jpg": { "embedding": [0.123, -0.456, ...], ... } }
â”‚
â”œâ”€â”€ analysis_clustering_analysis_test_data.cache
â”‚   â””â”€â”€ { "n_clusters": 5, "cluster_labels": [0,1,2,...], ... }
â”‚
â”œâ”€â”€ baseline_attribute_analysis_test_data.cache
â”‚   â””â”€â”€ Baseline ì‹œì ì˜ ì†ì„± ë¶„ì„ ê²°ê³¼ (ìŠ¤ëƒ…ìƒ·)
â”‚
â”œâ”€â”€ baseline_embedding_analysis_test_data.cache
â”‚   â””â”€â”€ Baseline ì‹œì ì˜ ì„ë² ë”© ê²°ê³¼ (ìŠ¤ëƒ…ìƒ·)
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ attribute_analysis.png      # 2x3 grid
â”‚   â”œâ”€â”€ embedding_pca_3d.png        # 3D scatter
â”‚   â””â”€â”€ cluster_analysis.png        # 1x2 grid
â”‚
â”œâ”€â”€ drift/
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”œâ”€â”€ attribute_drift.png     # 2x3 grid
â”‚   â”‚   â”œâ”€â”€ embedding_drift_3d.png  # 3D overlay
â”‚   â”‚   â””â”€â”€ drift_scores.png        # Bar chart
â”‚   â”œâ”€â”€ timeline.tsv
â”‚   â”‚   â””â”€â”€ timestamp | overall_score | status | files_added | files_removed
â”‚   â””â”€â”€ metrics.json
â”‚       â””â”€â”€ { "size": {...}, "noise": {...}, "embedding": {...}, "overall_score": 0.08 }
â”‚
â””â”€â”€ metrics.json
    â””â”€â”€ { "num_files": 100, "avg_size_mb": 2.3, "avg_quality_score": 65.3, ... }
```

---

## ğŸ”„ ì²˜ë¦¬ íë¦„

### **analyze_with_ddoc.py**

```python
1. params.yaml ë¡œë“œ
   â””â”€> ë°ì´í„°ì…‹ ê²½ë¡œ, í˜•ì‹, ì„ë² ë”© ëª¨ë¸ ë“±

2. ì†ì„± ë¶„ì„ (Step 1)
   â”œâ”€> run_attribute_analysis_wrapper([data_dir], formats)
   â”‚   â””â”€> ddoc ëª¨ë“ˆì´ íŒŒì¼ í•´ì‹œ ê³„ì‚° â†’ ìºì‹œ í™•ì¸
   â”‚       â”œâ”€ ìºì‹œ ìˆìŒ: ìŠ¤í‚µ
   â”‚       â””â”€ ìºì‹œ ì—†ìŒ: ë¶„ì„ (í¬ê¸°, í•´ìƒë„, ë…¸ì´ì¦ˆ, ì„ ëª…ë„)
   â”‚
   â”œâ”€> validate_cache() í˜¸ì¶œ
   â”‚   â””â”€> ì‚­ì œëœ íŒŒì¼ì˜ orphan cache ì œê±°
   â”‚
   â””â”€> ì‹œê°í™” ìƒì„± (matplotlib)
       â””â”€> cache/plots/attribute_analysis.png (6ê°œ subplot)

3. ì„ë² ë”© ë¶„ì„ (Step 2)
   â”œâ”€> run_embedding_analysis([data_dir], model="ViT-B/16")
   â”‚   â””â”€> CLIP ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ
   â”‚
   â””â”€> PCA 3D ì‹œê°í™”
       â””â”€> cache/plots/embedding_pca_3d.png

4. í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ (Step 3)
   â”œâ”€> K-means ë˜ëŠ” DBSCAN
   â”œâ”€> Silhouette scoreë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ
   â””â”€> cache/plots/cluster_analysis.png

5. ë©”íŠ¸ë¦­ ì €ì¥
   â””â”€> cache/metrics.json
```

### **detect_drift.py**

```python
1. Baseline ë¡œë“œ
   â”œâ”€> cache/baseline_*.cache íŒŒì¼ í™•ì¸
   â””â”€> ì—†ìœ¼ë©´ í˜„ì¬ ìƒíƒœë¥¼ Baselineìœ¼ë¡œ ì €ì¥

2. íŒŒì¼ ë³€ê²½ ì‚¬í•­ ë¶„ì„
   â”œâ”€> added = current - baseline
   â”œâ”€> removed = baseline - current
   â””â”€> common = baseline âˆ© current

3. ì†ì„± ë“œë¦¬í”„íŠ¸ ë¶„ì„
   â”œâ”€> KL Divergence ê³„ì‚° (í¬ê¸°, ë…¸ì´ì¦ˆ, ì„ ëª…ë„, í’ˆì§ˆ)
   â”œâ”€> Wasserstein Distance
   â”œâ”€> KS Test
   â””â”€> í’ˆì§ˆ ìƒíƒœ íŒì • (DEGRADED/STABLE/IMPROVED)

4. ì„ë² ë”© ë“œë¦¬í”„íŠ¸ ë¶„ì„
   â”œâ”€> MMD (Maximum Mean Discrepancy)
   â”œâ”€> Mean Shift (ì¤‘ì‹¬ì  ì´ë™)
   â””â”€> Variance Change

5. Overall Drift Score ê³„ì‚°
   â””â”€> ê°€ì¤‘ í‰ê·  â†’ NORMAL/WARNING/CRITICAL

6. ì‹œê°í™” ìƒì„±
   â”œâ”€> cache/drift/plots/attribute_drift.png (6ê°œ subplot)
   â”œâ”€> cache/drift/plots/embedding_drift_3d.png
   â””â”€> cache/drift/plots/drift_scores.png

7. íƒ€ì„ë¼ì¸ ì—…ë°ì´íŠ¸
   â””â”€> cache/drift/timeline.tsv (append)
```

---

## ğŸ“ ì•Œê³ ë¦¬ì¦˜

### **í’ˆì§ˆ ìŠ¤ì½”ì–´ ê³„ì‚°**

```python
def calculate_quality_score(sharpness, noise_level):
    """
    ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (0-100)
    
    Args:
        sharpness: ì„ ëª…ë„ (Laplacian variance, 0~100+)
        noise_level: ë…¸ì´ì¦ˆ ë ˆë²¨ (í‘œì¤€í¸ì°¨, 0~50+)
    
    Returns:
        quality: 0-100 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    """
    sharp_norm = min(sharpness / 100, 1.0)     # 0-1 ì •ê·œí™”
    noise_norm = max(0, 1.0 - (noise_level / 50))  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    
    quality = (sharp_norm * 0.6 + noise_norm * 0.4) * 100
    return quality
```

### **KL Divergence**

```python
def calculate_kl_divergence(p, q, bins=20):
    """
    Kullback-Leibler Divergence
    
    KL(P||Q) = Î£ P(i) * log(P(i) / Q(i))
    
    ë‚®ì„ìˆ˜ë¡ ë¶„í¬ê°€ ìœ ì‚¬í•¨
    """
    p_hist, edges = np.histogram(p, bins=bins, density=True)
    q_hist, _ = np.histogram(q, bins=edges, density=True)
    
    # Add small epsilon to avoid log(0)
    p_hist = p_hist + 1e-10
    q_hist = q_hist + 1e-10
    
    kl = np.sum(p_hist * np.log(p_hist / q_hist))
    return float(kl)
```

### **MMD (Maximum Mean Discrepancy)**

```python
def calculate_mmd(X, Y):
    """
    ë‘ ë¶„í¬ ê°„ ê±°ë¦¬ ì¸¡ì • (ì„ë² ë”© ê³µê°„)
    
    MMDÂ² = E[k(x,x')] - 2E[k(x,y)] + E[k(y,y')]
    
    where k is RBF kernel
    """
    def rbf_kernel(X, Y, gamma=1.0):
        XX = np.sum(X**2, axis=1).reshape(-1, 1)
        YY = np.sum(Y**2, axis=1).reshape(1, -1)
        XY = np.dot(X, Y.T)
        return np.exp(-gamma * (XX - 2*XY + YY))
    
    K_XX = rbf_kernel(X, X)
    K_YY = rbf_kernel(Y, Y)
    K_XY = rbf_kernel(X, Y)
    
    mmd = K_XX.mean() - 2*K_XY.mean() + K_YY.mean()
    return float(np.sqrt(max(mmd, 0)))
```

---

## âš™ï¸ ì„¤ì • ìƒì„¸

### **params.yaml**

```yaml
# ë°ì´í„°ì…‹ ì •ì˜
datasets:
  - name: test_data
    path: datasets/test_data
    formats: ['.jpg', '.jpeg', '.png']
    description: "Test dataset for drift detection"

# ì„ë² ë”© ì„¤ì •
embedding:
  model: "ViT-B/16"           # CLIP ëª¨ë¸
  device: "cpu"               # "cuda" for GPU
  batch_size: 32              # ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)

# í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •
clustering:
  method: "kmeans"            # "kmeans" or "dbscan"
  n_clusters: null            # null = auto selection
  selection_method: "silhouette"  # "silhouette", "elbow", "davies_bouldin"
  n_clusters_range: [2, 10]  # auto selection ë²”ìœ„

# ë“œë¦¬í”„íŠ¸ ì„ê³„ê°’
drift:
  threshold_warning: 0.15     # WARNING ê¸°ì¤€
  threshold_critical: 0.25    # CRITICAL ê¸°ì¤€
  enable_auto_baseline: true  # ì²« ì‹¤í–‰ ì‹œ ìë™ Baseline ì„¤ì •
  
  # ë©”íŠ¸ë¦­ë³„ ê°€ì¤‘ì¹˜ (í•©=1.0)
  weights:
    size: 0.15
    noise: 0.15
    sharpness: 0.15
    quality: 0.15
    embedding: 0.40
```

### **dvc.yaml**

```yaml
stages:
  analyze_test_data:
    cmd: python analyze_with_ddoc.py test_data
    deps:
      - datasets/test_data        # ë°ì´í„° ë³€ê²½ ê°ì§€
      - analyze_with_ddoc.py      # ìŠ¤í¬ë¦½íŠ¸ ë³€ê²½ ê°ì§€
    params:
      - analysis
      - embedding
      - clustering
    outs:
      - datasets/test_data/cache/plots/:
          cache: false            # DVC ìºì‹œì— ì €ì¥ ì•ˆí•¨
      - datasets/test_data/cache/metrics.json:
          cache: false
    plots:
      - datasets/test_data/cache/plots/  # VSCode í”ŒëŸ¬ê·¸ì¸ì´ ì¸ì‹
  
  detect_drift_test_data:
    cmd: python detect_drift.py test_data
    deps:
      - datasets/test_data
      - detect_drift.py
    params:
      - drift
    outs:
      - datasets/test_data/cache/drift/plots/:
          cache: false
      - datasets/test_data/cache/drift/metrics.json:
          cache: false
    plots:
      - datasets/test_data/cache/drift/plots/
      - datasets/test_data/cache/drift/timeline.tsv:
          x: timestamp          # Xì¶•
          y: overall_score      # Yì¶•
          template: linear      # ë¼ì¸ ì°¨íŠ¸
```

---

## ğŸ” ë³´ì•ˆ ë° ì„±ëŠ¥

### **ìºì‹œ ë¬´ê²°ì„±**

- **í•´ì‹œ ê¸°ë°˜**: íŒŒì¼ ë‚´ìš© ë³€ê²½ ì‹œ ìë™ìœ¼ë¡œ ì¬ë¶„ì„
- **Orphan ì •ë¦¬**: ì‚­ì œëœ íŒŒì¼ì˜ ìºì‹œ ìë™ ì œê±°
- **Baseline ë³´í˜¸**: `baseline_*.cache`ëŠ” ëª…ì‹œì  ì‚­ì œ ì „ê¹Œì§€ ìœ ì§€

### **ì„±ëŠ¥ ìµœì í™”**

1. **ì¦ë¶„ ë¶„ì„**: ë³€ê²½ëœ íŒŒì¼ë§Œ ì¬ë¶„ì„
2. **ë°°ì¹˜ ì²˜ë¦¬**: ì„ë² ë”© ì¶”ì¶œ ì‹œ ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬
3. **ìºì‹œ ìš°ì„ **: í•´ì‹œ ë§¤ì¹­ ì‹œ ë¶„ì„ ìŠ¤í‚µ
4. **ë³‘ë ¬ ì²˜ë¦¬**: ddoc ë‚´ë¶€ì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš© (ì„ íƒ)

### **ë©”ëª¨ë¦¬ ê´€ë¦¬**

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œ
embedding:
  batch_size: 16      # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ê°ì†Œ
  device: "cuda"      # GPU ì‚¬ìš© ê¶Œì¥
```

---

## ğŸ› ë””ë²„ê¹…

### **ë¡œê·¸ ë ˆë²¨ ì„¤ì •**

```python
# analyze_with_ddoc.py ìƒë‹¨ì— ì¶”ê°€
import logging
logging.basicConfig(level=logging.DEBUG)
```

### **ìºì‹œ í™•ì¸**

```bash
# ìºì‹œ íŒŒì¼ ë‚´ìš© í™•ì¸
python -c "
import pickle
with open('datasets/test_data/cache/analysis_attribute_analysis_test_data.cache', 'rb') as f:
    data = pickle.load(f)
    print(f'Files: {len(data)}')
    print(f'Sample: {list(data.items())[0]}')
"
```

### **ë“œë¦¬í”„íŠ¸ ë©”íŠ¸ë¦­ í™•ì¸**

```bash
# JSON í¬ë§·íŒ…
cat datasets/test_data/cache/drift/metrics.json | python -m json.tool
```

---

## ğŸ”„ í™•ì¥ ê°€ëŠ¥ì„±

### **ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€**

```python
# analyze_with_ddoc.pyì— ì¶”ê°€
def calculate_custom_metric(image_path):
    img = cv2.imread(image_path)
    # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê³„ì‚°
    return metric_value

# ì†ì„± ë¶„ì„ì— í†µí•©
attr_cache[filename]['custom_metric'] = calculate_custom_metric(file_path)
```

### **ìƒˆë¡œìš´ ë“œë¦¬í”„íŠ¸ ê²€ì¶œ ë°©ë²•**

```python
# detect_drift.pyì— ì¶”ê°€
def calculate_custom_drift(baseline, current):
    # ì»¤ìŠ¤í…€ ë“œë¦¬í”„íŠ¸ ê³„ì‚°
    return drift_score

# Overall Scoreì— í†µí•©
custom_drift = calculate_custom_drift(baseline_data, current_data)
overall_score += custom_drift * custom_weight
```

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- **CLIP**: Learning Transferable Visual Models From Natural Language Supervision (OpenAI, 2021)
- **KL Divergence**: Information Theory and Statistics
- **MMD**: A Kernel Two-Sample Test (Gretton et al., 2012)
- **DVC**: Data Version Control (iterative.ai)

