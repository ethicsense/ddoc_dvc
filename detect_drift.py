#!/usr/bin/env python3
"""
Baselineê³¼ Current ë°ì´í„°ì…‹ ë¹„êµ ë“œë¦¬í”„íŠ¸ íƒì§€
ddoc ìºì‹œë¥¼ ì§ì ‘ í™œìš©
"""
import sys
import os
from pathlib import Path
from datetime import datetime
import json
import pickle
import yaml
import numpy as np

# ddoc ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent.parent / 'datadrift_app_engine'))

try:
    from cache_utils import get_cached_analysis_data, save_analysis_data
    print("âœ… ddoc ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ddoc ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def calculate_kl_divergence(p, q, bins=20):
    """KL Divergence ê³„ì‚°"""
    p_hist, edges = np.histogram(p, bins=bins, density=True)
    q_hist, _ = np.histogram(q, bins=edges, density=True)
    
    # 0 ë°©ì§€
    p_hist = p_hist + 1e-10
    q_hist = q_hist + 1e-10
    
    # ì •ê·œí™”
    p_hist = p_hist / p_hist.sum()
    q_hist = q_hist / q_hist.sum()
    
    return float(np.sum(p_hist * np.log(p_hist / q_hist)))

def calculate_mmd(X, Y, gamma=1.0):
    """Maximum Mean Discrepancy ê³„ì‚°"""
    XX = np.dot(X, X.T)
    YY = np.dot(Y, Y.T)
    XY = np.dot(X, Y.T)
    
    X_sqnorms = np.diagonal(XX)
    Y_sqnorms = np.diagonal(YY)
    
    def rbf_kernel(X_sqnorms, Y_sqnorms, XY):
        K = -2 * XY + X_sqnorms[:, None] + Y_sqnorms[None, :]
        K = np.exp(-gamma * K)
        return K
    
    K_XX = rbf_kernel(X_sqnorms, X_sqnorms, XX)
    K_YY = rbf_kernel(Y_sqnorms, Y_sqnorms, YY)
    K_XY = rbf_kernel(X_sqnorms, Y_sqnorms, XY)
    
    m = X.shape[0]
    n = Y.shape[0]
    
    mmd = (K_XX.sum() - np.trace(K_XX)) / (m * (m - 1))
    mmd += (K_YY.sum() - np.trace(K_YY)) / (n * (n - 1))
    mmd -= 2 * K_XY.sum() / (m * n)
    
    return float(np.sqrt(max(mmd, 0)))

def detect_drift(dataset_name=None):
    """Baselineê³¼ Current ë¹„êµí•˜ì—¬ ë“œë¦¬í”„íŠ¸ íƒì§€ (ë°ì´í„°ì…‹ë³„ ë…ë¦½ ê´€ë¦¬)
    
    Args:
        dataset_name: ë¶„ì„í•  ë°ì´í„°ì…‹ ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    """
    
    # params.yaml ë¡œë“œ
    with open('params.yaml', 'r') as f:
        params = yaml.safe_load(f)
    
    # ë°ì´í„°ì…‹ ì •ë³´ ì¶”ì¶œ
    if dataset_name:
        dataset_config = next(
            (ds for ds in params.get('datasets', []) if ds['name'] == dataset_name),
            None
        )
        if not dataset_config:
            print(f"âŒ ë°ì´í„°ì…‹ '{dataset_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        data_dir = Path(dataset_config['path'])
    else:
        data_dir = Path(params['analysis']['data_dir'])
    
    dataset_name_only = data_dir.name  # "test_data"
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ datasets ë°–ì˜ analysis/ ë””ë ‰í† ë¦¬ì— ì €ì¥
    analysis_root = Path("analysis") / dataset_name_only
    drift_dir = analysis_root / "drift"
    drift_dir.mkdir(parents=True, exist_ok=True)
    
    plot_dir = drift_dir / "plots"
    plot_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ” ë“œë¦¬í”„íŠ¸ íƒì§€ ì‹œì‘")
    print(f"=" * 80)
    
    # Baseline ë¡œë“œ
    baseline_attr = get_cached_analysis_data(data_dir, "attribute_analysis_baseline")
    baseline_emb = get_cached_analysis_data(data_dir, "embedding_analysis_baseline")
    
    # Current ë¡œë“œ
    current_attr = get_cached_analysis_data(data_dir, "attribute_analysis")
    current_emb = get_cached_analysis_data(data_dir, "embedding_analysis")
    
    # Baselineì´ ì—†ìœ¼ë©´ í˜„ì¬ë¥¼ baselineìœ¼ë¡œ ì„¤ì •
    if not baseline_attr and current_attr:
        print("âš ï¸ Baselineì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ Baselineìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        save_analysis_data(data_dir, current_attr, "attribute_analysis_baseline")
        if current_emb:
            save_analysis_data(data_dir, current_emb, "embedding_analysis_baseline")
        
        # ì´ˆê¸° ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'timestamp': timestamp,
            'status': 'BASELINE_CREATED',
            'num_files': len(current_attr)
        }
        
        with open(drift_dir / 'metrics.json', 'w') as f:
            json.dump(metrics, f, indent=2)
        
        # ì´ˆê¸° timeline.tsv ìƒì„± (DVC plots ì˜¤ë¥˜ ë°©ì§€)
        timeline_file = drift_dir / "timeline.tsv"
        with open(timeline_file, 'w') as f:
            f.write("timestamp\toverall_score\tstatus\tfiles_added\tfiles_removed\n")
            f.write(f"{timestamp}\t0.00\tBASELINE\t0\t0\n")
        
        # ë¹ˆ plots ë””ë ‰í† ë¦¬ì— placeholder ìƒì„± (DVC ì˜¤ë¥˜ ë°©ì§€)
        placeholder = plot_dir / ".gitkeep"
        placeholder.touch()
        
        print("âœ… Baseline ì„¤ì • ì™„ë£Œ")
        print(f"   ğŸ“ timeline.tsv ì´ˆê¸°í™”: {timeline_file}")
        return
    
    # ë“œë¦¬í”„íŠ¸ ë¶„ì„ ì‹œì‘
    drift_metrics = {}
    
    # íŒŒì¼ ë³€ê²½ ì‚¬í•­ ë¶„ì„
    ref_files = set(baseline_attr.keys())
    cur_files = set(current_attr.keys())
    
    added = cur_files - ref_files
    removed = ref_files - cur_files
    common = ref_files & cur_files
    
    
    print(f"ğŸ“Š íŒŒì¼ ë³€ê²½ ì‚¬í•­:")
    print(f"   ì¶”ê°€: {len(added)}ê°œ")
    print(f"   ì‚­ì œ: {len(removed)}ê°œ")
    print(f"   ê³µí†µ: {len(common)}ê°œ")
    print(f"   Total: {len(ref_files)} â†’ {len(cur_files)}")
    print()
    
    drift_metrics = {}
    
    # 1. ì†ì„± ë“œë¦¬í”„íŠ¸ ë¶„ì„
    print("ğŸ“ˆ Attribute Drift Analysis:")
    print("-" * 80)
    
    if common:
        # íŒŒì¼ í¬ê¸° ë“œë¦¬í”„íŠ¸
        ref_sizes = [baseline_attr[f]['size'] for f in common if 'size' in baseline_attr[f]]
        cur_sizes = [current_attr[f]['size'] for f in common if 'size' in current_attr[f]]
        
        # ë…¸ì´ì¦ˆ ë ˆë²¨ ë“œë¦¬í”„íŠ¸
        ref_noise = [baseline_attr[f]['noise_level'] for f in common if 'noise_level' in baseline_attr[f]]
        cur_noise = [current_attr[f]['noise_level'] for f in common if 'noise_level' in current_attr[f]]
        
        # ì„ ëª…ë„ ë“œë¦¬í”„íŠ¸
        ref_sharp = [baseline_attr[f]['sharpness'] for f in common if 'sharpness' in baseline_attr[f]]
        cur_sharp = [current_attr[f]['sharpness'] for f in common if 'sharpness' in current_attr[f]]
        
        from scipy.stats import wasserstein_distance, ks_2samp
        
        # í¬ê¸° ë“œë¦¬í”„íŠ¸
        if ref_sizes and cur_sizes:
            size_kl = calculate_kl_divergence(ref_sizes, cur_sizes)
            size_wd = wasserstein_distance(ref_sizes, cur_sizes)
            size_ks = ks_2samp(ref_sizes, cur_sizes)
            
            drift_metrics['size'] = {
                'kl_divergence': size_kl,
                'wasserstein_distance': float(size_wd),
                'ks_statistic': float(size_ks.statistic),
                'ks_pvalue': float(size_ks.pvalue)
            }
            
            
            print(f"   í¬ê¸° KL Divergence: {size_kl:.4f}")
            print(f"   í¬ê¸° Wasserstein: {size_wd:.4f}")
        
        # ë…¸ì´ì¦ˆ ë“œë¦¬í”„íŠ¸
        if ref_noise and cur_noise:
            noise_kl = calculate_kl_divergence(ref_noise, cur_noise)
            noise_wd = wasserstein_distance(ref_noise, cur_noise)
            
            drift_metrics['noise'] = {
                'kl_divergence': noise_kl,
                'wasserstein_distance': float(noise_wd),
                'mean_change': float(np.mean(cur_noise) - np.mean(ref_noise))
            }
            
            
            print(f"   ë…¸ì´ì¦ˆ KL Divergence: {noise_kl:.4f}")
            print(f"   ë…¸ì´ì¦ˆ í‰ê·  ë³€í™”: {drift_metrics['noise']['mean_change']:.4f}")
        
        # ì„ ëª…ë„ ë“œë¦¬í”„íŠ¸
        if ref_sharp and cur_sharp:
            sharp_kl = calculate_kl_divergence(ref_sharp, cur_sharp)
            sharp_wd = wasserstein_distance(ref_sharp, cur_sharp)
            
            drift_metrics['sharpness'] = {
                'kl_divergence': sharp_kl,
                'wasserstein_distance': float(sharp_wd),
                'mean_change': float(np.mean(cur_sharp) - np.mean(ref_sharp))
            }
            
            
            print(f"   ì„ ëª…ë„ KL Divergence: {sharp_kl:.4f}")
            print(f"   ì„ ëª…ë„ í‰ê·  ë³€í™”: {drift_metrics['sharpness']['mean_change']:.4f}")
        
        # ì¢…í•© í’ˆì§ˆ ìŠ¤ì½”ì–´ ë“œë¦¬í”„íŠ¸
        if ref_noise and ref_sharp and cur_noise and cur_sharp:
            def calculate_quality_score(sharpness, noise_level):
                """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0~100, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
                sharp_norm = min(sharpness / 100, 1.0)
                noise_norm = max(0, 1.0 - (noise_level / 50))
                quality = (sharp_norm * 0.6 + noise_norm * 0.4) * 100
                return quality
            
            ref_quality = [calculate_quality_score(s, n) for s, n in zip(ref_sharp, ref_noise)]
            cur_quality = [calculate_quality_score(s, n) for s, n in zip(cur_sharp, cur_noise)]
            
            quality_kl = calculate_kl_divergence(ref_quality, cur_quality)
            quality_mean_change = np.mean(cur_quality) - np.mean(ref_quality)
            
            # í’ˆì§ˆ ìƒíƒœ íŒì •
            if quality_mean_change < -10:
                quality_status = "DEGRADED"
            elif quality_mean_change > 10:
                quality_status = "IMPROVED"
            else:
                quality_status = "STABLE"
            
            drift_metrics['quality'] = {
                'kl_divergence': quality_kl,
                'mean_change': float(quality_mean_change),
                'baseline_mean': float(np.mean(ref_quality)),
                'current_mean': float(np.mean(cur_quality)),
                'status': quality_status
            }
            
            
            print(f"   ì¢…í•© í’ˆì§ˆ KL Divergence: {quality_kl:.4f}")
            print(f"   ì¢…í•© í’ˆì§ˆ í‰ê· : {np.mean(ref_quality):.2f} â†’ {np.mean(cur_quality):.2f} ({quality_mean_change:+.2f})")
            print(f"   í’ˆì§ˆ ìƒíƒœ: {quality_status}")
            
            # ì‹œê°í™”: ì†ì„± ë“œë¦¬í”„íŠ¸ (ê°œë³„ ì°¨íŠ¸ë¡œ ì €ì¥)
            import matplotlib.pyplot as plt
            
            # 1. í¬ê¸° ë“œë¦¬í”„íŠ¸
            plt.figure(figsize=(10, 6))
            plt.hist(ref_sizes, bins=20, alpha=0.6, label='Baseline', color='blue', edgecolor='black')
            plt.hist(cur_sizes, bins=20, alpha=0.6, label='Current', color='red', edgecolor='black')
            plt.title(f'Size Drift (KL={size_kl:.4f})', fontsize=14, fontweight='bold')
            plt.xlabel('Size (MB)')
            plt.ylabel('Count')
            plt.legend()
            plt.grid(alpha=0.3)
            plt.tight_layout()
            plt.savefig(plot_dir / 'size_drift.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. ë…¸ì´ì¦ˆ ë“œë¦¬í”„íŠ¸
            if ref_noise and cur_noise:
                plt.figure(figsize=(10, 6))
                plt.hist(ref_noise, bins=20, alpha=0.6, label='Baseline', color='blue', edgecolor='black')
                plt.hist(cur_noise, bins=20, alpha=0.6, label='Current', color='red', edgecolor='black')
                plt.title(f'Noise Drift (KL={noise_kl:.4f})', fontsize=14, fontweight='bold')
                plt.xlabel('Noise Level')
                plt.ylabel('Count')
                plt.legend()
                plt.grid(alpha=0.3)
                plt.tight_layout()
                plt.savefig(plot_dir / 'noise_drift.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 3. ì„ ëª…ë„ ë“œë¦¬í”„íŠ¸
            if ref_sharp and cur_sharp:
                plt.figure(figsize=(10, 6))
                plt.hist(ref_sharp, bins=20, alpha=0.6, label='Baseline', color='blue', edgecolor='black')
                plt.hist(cur_sharp, bins=20, alpha=0.6, label='Current', color='red', edgecolor='black')
                plt.title(f'Sharpness Drift (KL={sharp_kl:.4f})', fontsize=14, fontweight='bold')
                plt.xlabel('Sharpness')
                plt.ylabel('Count')
                plt.legend()
                plt.grid(alpha=0.3)
                plt.tight_layout()
                plt.savefig(plot_dir / 'sharpness_drift.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 4. í’ˆì§ˆ ë§µ ë“œë¦¬í”„íŠ¸
            if ref_noise and ref_sharp and cur_noise and cur_sharp:
                plt.figure(figsize=(10, 8))
                plt.scatter(ref_noise, ref_sharp, alpha=0.5, s=80, 
                          label='Baseline', color='blue', edgecolors='darkblue')
                plt.scatter(cur_noise, cur_sharp, alpha=0.5, s=80, 
                          label='Current', color='red', edgecolors='darkred')
                plt.title('Quality Map Drift', fontsize=14, fontweight='bold')
                plt.xlabel('Noise Level')
                plt.ylabel('Sharpness')
                plt.legend()
                plt.grid(alpha=0.3)
                plt.tight_layout()
                plt.savefig(plot_dir / 'quality_map_drift.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 5. í’ˆì§ˆ ìŠ¤ì½”ì–´ ë“œë¦¬í”„íŠ¸
            if 'quality' in drift_metrics:
                status_color = {'DEGRADED': 'red', 'STABLE': 'green', 'IMPROVED': 'blue'}
                title_color = status_color.get(quality_status, 'black')
                
                plt.figure(figsize=(10, 6))
                plt.hist(ref_quality, bins=20, alpha=0.6, label='Baseline', color='blue', edgecolor='black')
                plt.hist(cur_quality, bins=20, alpha=0.6, label='Current', color='red', edgecolor='black')
                plt.title(f'Quality Score Drift - {quality_status}\n(KL={quality_kl:.4f}, Î”={quality_mean_change:+.2f})', 
                         fontsize=14, fontweight='bold', color=title_color)
                plt.xlabel('Quality Score (0-100)')
                plt.ylabel('Count')
                plt.axvline(30, color='red', linestyle='--', alpha=0.3, linewidth=1, label='Poor')
                plt.axvline(50, color='orange', linestyle='--', alpha=0.3, linewidth=1, label='Fair')
                plt.axvline(70, color='green', linestyle='--', alpha=0.3, linewidth=1, label='Good')
                plt.legend()
                plt.grid(alpha=0.3)
                plt.tight_layout()
                plt.savefig(plot_dir / 'quality_score_drift.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 6. í’ˆì§ˆ ìŠ¤ì½”ì–´ ë°•ìŠ¤í”Œë¡¯
            if 'quality' in drift_metrics:
                plt.figure(figsize=(10, 6))
                box_data = [ref_quality, cur_quality]
                bp = plt.boxplot(box_data, labels=['Baseline', 'Current'], patch_artist=True)
                bp['boxes'][0].set_facecolor('lightblue')
                bp['boxes'][1].set_facecolor('lightcoral')
                plt.title('Quality Score Comparison', fontsize=14, fontweight='bold')
                plt.ylabel('Quality Score (0-100)')
                plt.grid(alpha=0.3, axis='y')
                plt.tight_layout()
                plt.savefig(plot_dir / 'quality_score_boxplot.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            print(f"   ğŸ“Š ì†ì„± ë“œë¦¬í”„íŠ¸ ì‹œê°í™” ì €ì¥: {plot_dir}/*.png (6ê°œ íŒŒì¼)")
    
    print()
    
    # 2. ì„ë² ë”© ë“œë¦¬í”„íŠ¸ ë¶„ì„
    print("ğŸ”¬ Embedding Drift Analysis:")
    print("-" * 80)
    
    if baseline_emb and current_emb:
        ref_embeddings = np.array([v['embedding'] for v in baseline_emb.values() if 'embedding' in v])
        cur_embeddings = np.array([v['embedding'] for v in current_emb.values() if 'embedding' in v])
        
        if len(ref_embeddings) > 0 and len(cur_embeddings) > 0:
            # MMD ê³„ì‚°
            mmd = calculate_mmd(ref_embeddings, cur_embeddings)
            
            # Mean shift
            ref_mean = ref_embeddings.mean(axis=0)
            cur_mean = cur_embeddings.mean(axis=0)
            mean_shift = float(np.linalg.norm(ref_mean - cur_mean))
            
            # ë¶„ì‚° ë³€í™”
            ref_var = float(np.var(ref_embeddings))
            cur_var = float(np.var(cur_embeddings))
            variance_ratio = abs(cur_var - ref_var) / ref_var if ref_var > 0 else 0
            
            drift_metrics['embedding'] = {
                'mmd': mmd,
                'mean_shift': mean_shift,
                'variance_change': float(variance_ratio),
                'baseline_variance': ref_var,
                'current_variance': cur_var
            }
            
            
            print(f"   MMD: {mmd:.4f}")
            print(f"   Mean Shift: {mean_shift:.4f}")
            print(f"   Variance Change: {variance_ratio:.1%}")
            
            # ì‹œê°í™”: PCA 3D Overlay
            from sklearn.decomposition import PCA
            from mpl_toolkits.mplot3d import Axes3D
            
            all_emb = np.vstack([ref_embeddings, cur_embeddings])
            pca = PCA(n_components=3)
            all_pca = pca.fit_transform(all_emb)
            
            ref_pca = all_pca[:len(ref_embeddings)]
            cur_pca = all_pca[len(ref_embeddings):]
            
            fig = plt.figure(figsize=(14, 10))
            ax = fig.add_subplot(111, projection='3d')
            
            # ë°ì´í„° í¬ì¸íŠ¸
            ax.scatter(ref_pca[:, 0], ref_pca[:, 1], ref_pca[:, 2],
                      alpha=0.5, s=80, label='Baseline', color='blue', 
                      edgecolors='darkblue', linewidth=0.5)
            ax.scatter(cur_pca[:, 0], cur_pca[:, 1], cur_pca[:, 2],
                      alpha=0.5, s=80, label='Current', color='red', 
                      edgecolors='darkred', linewidth=0.5)
            
            # ì¤‘ì‹¬ì 
            ref_center = ref_pca.mean(axis=0)
            cur_center = cur_pca.mean(axis=0)
            ax.scatter(*ref_center, s=400, marker='*', color='darkblue', 
                      edgecolors='black', linewidth=2, label='Baseline Center', zorder=5)
            ax.scatter(*cur_center, s=400, marker='*', color='darkred', 
                      edgecolors='black', linewidth=2, label='Current Center', zorder=5)
            
            # ì´ë™ ë²¡í„° (3D)
            if np.linalg.norm(cur_center - ref_center) > 0.1:
                from mpl_toolkits.mplot3d.art3d import Line3D
                line = Line3D([ref_center[0], cur_center[0]], 
                             [ref_center[1], cur_center[1]],
                             [ref_center[2], cur_center[2]], 
                             color='green', linewidth=3, label='Shift Vector')
                ax.add_line(line)
            
            ax.set_title(f'Embedding Space Drift (MMD={mmd:.4f})', 
                        fontsize=14, fontweight='bold')
            ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
            ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
            ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%})')
            ax.legend(loc='upper left')
            ax.grid(alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(plot_dir / 'embedding_drift_3d.png', dpi=300, bbox_inches='tight')
            plt.close()
            print(f"   ğŸ“Š ì„ë² ë”© ë“œë¦¬í”„íŠ¸ 3D ì‹œê°í™” ì €ì¥: {plot_dir / 'embedding_drift_3d.png'}")
    
    print()
    
    # 3. ì „ì²´ ë“œë¦¬í”„íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚°
    print("ğŸ¯ Overall Drift Score:")
    print("-" * 80)
    
    size_kl = drift_metrics.get('size', {}).get('kl_divergence', 0)
    noise_kl = drift_metrics.get('noise', {}).get('kl_divergence', 0)
    sharp_kl = drift_metrics.get('sharpness', {}).get('kl_divergence', 0)
    quality_kl = drift_metrics.get('quality', {}).get('kl_divergence', 0)
    emb_mmd = drift_metrics.get('embedding', {}).get('mmd', 0)
    
    # ê°€ì¤‘ í‰ê·  (í’ˆì§ˆ ì§€í‘œ í¬í•¨)
    overall_score = (
        size_kl * 0.15 +           # í¬ê¸° 15%
        noise_kl * 0.15 +          # ë…¸ì´ì¦ˆ 15%
        sharp_kl * 0.15 +          # ì„ ëª…ë„ 15%
        quality_kl * 0.15 +        # ì¢…í•© í’ˆì§ˆ 15%
        emb_mmd * 0.40             # ì„ë² ë”© 40% (ê°€ì¥ ì¤‘ìš”)
    )
    
    drift_metrics['overall_score'] = float(overall_score)
    
    # ì„ê³„ê°’ ì²´í¬
    warning_threshold = params['drift']['threshold_warning']
    critical_threshold = params['drift']['threshold_critical']
    
    if overall_score > critical_threshold:
        status = 'CRITICAL'
        print(f"ğŸš¨ CRITICAL: {overall_score:.4f} > {critical_threshold}")
    elif overall_score > warning_threshold:
        status = 'WARNING'
        print(f"âš ï¸  WARNING: {overall_score:.4f} > {warning_threshold}")
    else:
        status = 'NORMAL'
        print(f"âœ… NORMAL: {overall_score:.4f}")
    
    drift_metrics['status'] = status
    drift_metrics['timestamp'] = timestamp
    
    # ë“œë¦¬í”„íŠ¸ ìŠ¤ì½”ì–´ ë°” ì°¨íŠ¸ (í’ˆì§ˆ ì§€í‘œ í¬í•¨)
    import matplotlib.pyplot as plt
    
    metrics_to_plot = {
        'Size': size_kl,
        'Noise': noise_kl,
        'Sharpness': sharp_kl,
        'Quality': quality_kl,
        'Embedding': emb_mmd,
        'Overall': overall_score
    }
    
    fig, ax = plt.subplots(figsize=(12, 6))
    colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum',
             'red' if overall_score > critical_threshold 
             else 'orange' if overall_score > warning_threshold else 'green']
    bars = ax.bar(metrics_to_plot.keys(), metrics_to_plot.values(), 
                 color=colors, alpha=0.7, edgecolor='black')
    
    ax.axhline(warning_threshold, color='orange', linestyle='--', 
              linewidth=2, label=f'Warning ({warning_threshold})')
    ax.axhline(critical_threshold, color='red', linestyle='--', 
              linewidth=2, label=f'Critical ({critical_threshold})')
    
    # ê°’ í‘œì‹œ
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    ax.set_title(f'Drift Metrics - {status}', fontsize=14, fontweight='bold')
    ax.set_ylabel('Drift Score')
    ax.legend()
    ax.grid(alpha=0.3, axis='y')
    plt.tight_layout()
    plt.savefig(plot_dir / 'drift_scores.png', dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   ğŸ“Š ë“œë¦¬í”„íŠ¸ ìŠ¤ì½”ì–´ ì‹œê°í™” ì €ì¥: {plot_dir / 'drift_scores.png'}")
    
    # ê²°ê³¼ ì €ì¥
    with open(drift_dir / 'metrics.json', 'w') as f:
        json.dump(drift_metrics, f, indent=2)
    
    # ë“œë¦¬í”„íŠ¸ íƒ€ì„ë¼ì¸ ì—…ë°ì´íŠ¸ (TSV for DVC plots)
    timeline_file = drift_dir / "timeline.tsv"
    
    # ê¸°ì¡´ íƒ€ì„ë¼ì¸ ë¡œë“œ ë˜ëŠ” ìƒì„±
    if timeline_file.exists():
        with open(timeline_file, 'r') as f:
            lines = f.readlines()
    else:
        lines = ['timestamp\toverall_score\tstatus\tfiles_added\tfiles_removed\n']
    
    # ìƒˆ ë°ì´í„° ì¶”ê°€
    lines.append(f"{timestamp}\t{overall_score:.4f}\t{status}\t{len(added)}\t{len(removed)}\n")
    
    with open(timeline_file, 'w') as f:
        f.writelines(lines)
    
    print()
    print("=" * 80)
    print(f"âœ… ë“œë¦¬í”„íŠ¸ íƒì§€ ì™„ë£Œ: {status}")
    print(f"   Overall Score: {overall_score:.4f}")
    print(f"   íŒŒì¼ ë³€ê²½: +{len(added)} -{len(removed)}")

if __name__ == "__main__":
    import sys
    
    # CLI ì¸ìë¡œ ë°ì´í„°ì…‹ ì§€ì • ê°€ëŠ¥
    dataset_name = sys.argv[1] if len(sys.argv) > 1 else None
    
    if dataset_name:
        print(f"ğŸ“¦ ë°ì´í„°ì…‹: {dataset_name}")
    else:
        print("ğŸ“¦ ê¸°ë³¸ ë°ì´í„°ì…‹ ì‚¬ìš©")
    
    detect_drift(dataset_name)
