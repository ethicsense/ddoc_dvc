#!/usr/bin/env python3
"""
Baselineê³¼ Current ë°ì´í„°ì…‹ ë¹„êµ ë“œë¦¬í”„íŠ¸ íƒì§€
ddoc ìºì‹œë¥¼ ì§ì ‘ í™œìš©
"""
import sys
import os
from pathlib import Path
from datetime import datetime
import json
import pickle
import yaml
import numpy as np

# ddoc ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent.parent / 'datadrift_app_engine'))

try:
    from cache_utils import get_cached_analysis_data, save_analysis_data
    from dvclive import Live
    print("âœ… ddoc ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ddoc ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def calculate_kl_divergence(p, q, bins=20):
    """KL Divergence ê³„ì‚°"""
    p_hist, edges = np.histogram(p, bins=bins, density=True)
    q_hist, _ = np.histogram(q, bins=edges, density=True)
    
    # 0 ë°©ì§€
    p_hist = p_hist + 1e-10
    q_hist = q_hist + 1e-10
    
    # ì •ê·œí™”
    p_hist = p_hist / p_hist.sum()
    q_hist = q_hist / q_hist.sum()
    
    return float(np.sum(p_hist * np.log(p_hist / q_hist)))

def calculate_mmd(X, Y, gamma=1.0):
    """Maximum Mean Discrepancy ê³„ì‚°"""
    XX = np.dot(X, X.T)
    YY = np.dot(Y, Y.T)
    XY = np.dot(X, Y.T)
    
    X_sqnorms = np.diagonal(XX)
    Y_sqnorms = np.diagonal(YY)
    
    def rbf_kernel(X_sqnorms, Y_sqnorms, XY):
        K = -2 * XY + X_sqnorms[:, None] + Y_sqnorms[None, :]
        K = np.exp(-gamma * K)
        return K
    
    K_XX = rbf_kernel(X_sqnorms, X_sqnorms, XX)
    K_YY = rbf_kernel(Y_sqnorms, Y_sqnorms, YY)
    K_XY = rbf_kernel(X_sqnorms, Y_sqnorms, XY)
    
    m = X.shape[0]
    n = Y.shape[0]
    
    mmd = (K_XX.sum() - np.trace(K_XX)) / (m * (m - 1))
    mmd += (K_YY.sum() - np.trace(K_YY)) / (n * (n - 1))
    mmd -= 2 * K_XY.sum() / (m * n)
    
    return float(np.sqrt(max(mmd, 0)))

def detect_drift():
    """Baselineê³¼ Current ë¹„êµí•˜ì—¬ ë“œë¦¬í”„íŠ¸ íƒì§€"""
    
    # params.yaml ë¡œë“œ
    with open('params.yaml', 'r') as f:
        params = yaml.safe_load(f)
    
    data_dir = params['analysis']['data_dir']
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    drift_dir = Path("analysis/drift")
    drift_dir.mkdir(parents=True, exist_ok=True)
    plot_dir = drift_dir / "plots"
    plot_dir.mkdir(exist_ok=True)
    
    print(f"ğŸ” ë“œë¦¬í”„íŠ¸ íƒì§€ ì‹œì‘")
    print(f"=" * 80)
    
    # Baseline ë¡œë“œ
    baseline_attr = get_cached_analysis_data(data_dir, "attribute_analysis_baseline")
    baseline_emb = get_cached_analysis_data(data_dir, "embedding_analysis_baseline")
    
    # Current ë¡œë“œ
    current_attr = get_cached_analysis_data(data_dir, "attribute_analysis")
    current_emb = get_cached_analysis_data(data_dir, "embedding_analysis")
    
    # Baselineì´ ì—†ìœ¼ë©´ í˜„ì¬ë¥¼ baselineìœ¼ë¡œ ì„¤ì •
    if not baseline_attr and current_attr:
        print("âš ï¸ Baselineì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ Baselineìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        save_analysis_data(data_dir, current_attr, "attribute_analysis_baseline")
        if current_emb:
            save_analysis_data(data_dir, current_emb, "embedding_analysis_baseline")
        
        # ì´ˆê¸° ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'timestamp': timestamp,
            'status': 'BASELINE_CREATED',
            'num_files': len(current_attr)
        }
        
        with open(drift_dir / 'metrics.json', 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print("âœ… Baseline ì„¤ì • ì™„ë£Œ")
        return
    
    # DVCLiveë¡œ ë“œë¦¬í”„íŠ¸ íŠ¸ë˜í‚¹
    with Live(dir=f"dvclive/drift_{timestamp}", save_dvc_exp=True) as live:
        live.log_param("timestamp", timestamp)
        
        # íŒŒì¼ ë³€ê²½ ì‚¬í•­ ë¶„ì„
        ref_files = set(baseline_attr.keys())
        cur_files = set(current_attr.keys())
        
        added = cur_files - ref_files
        removed = ref_files - cur_files
        common = ref_files & cur_files
        
        live.log_metric("files_added", len(added))
        live.log_metric("files_removed", len(removed))
        live.log_metric("files_common", len(common))
        live.log_metric("files_total_baseline", len(ref_files))
        live.log_metric("files_total_current", len(cur_files))
        
        print(f"ğŸ“Š íŒŒì¼ ë³€ê²½ ì‚¬í•­:")
        print(f"   ì¶”ê°€: {len(added)}ê°œ")
        print(f"   ì‚­ì œ: {len(removed)}ê°œ")
        print(f"   ê³µí†µ: {len(common)}ê°œ")
        print(f"   Total: {len(ref_files)} â†’ {len(cur_files)}")
        print()
        
        drift_metrics = {}
        
        # 1. ì†ì„± ë“œë¦¬í”„íŠ¸ ë¶„ì„
        print("ğŸ“ˆ Attribute Drift Analysis:")
        print("-" * 80)
        
        if common:
            ref_sizes = [baseline_attr[f]['size'] for f in common if 'size' in baseline_attr[f]]
            cur_sizes = [current_attr[f]['size'] for f in common if 'size' in current_attr[f]]
            
            if ref_sizes and cur_sizes:
                kl_div = calculate_kl_divergence(ref_sizes, cur_sizes)
                
                from scipy.stats import wasserstein_distance, ks_2samp
                wd = wasserstein_distance(ref_sizes, cur_sizes)
                ks_result = ks_2samp(ref_sizes, cur_sizes)
                
                drift_metrics['size'] = {
                    'kl_divergence': kl_div,
                    'wasserstein_distance': float(wd),
                    'ks_statistic': float(ks_result.statistic),
                    'ks_pvalue': float(ks_result.pvalue)
                }
                
                live.log_metric("drift/size/kl", kl_div)
                live.log_metric("drift/size/wasserstein", wd)
                live.log_metric("drift/size/ks_pvalue", ks_result.pvalue)
                
                print(f"   KL Divergence: {kl_div:.4f}")
                print(f"   Wasserstein Distance: {wd:.4f}")
                print(f"   KS Test p-value: {ks_result.pvalue:.4f}")
                
                # ì‹œê°í™”
                import matplotlib.pyplot as plt
                
                fig, ax = plt.subplots(figsize=(10, 5))
                ax.hist(ref_sizes, bins=20, alpha=0.6, label='Baseline', 
                       color='blue', edgecolor='black')
                ax.hist(cur_sizes, bins=20, alpha=0.6, label='Current', 
                       color='red', edgecolor='black')
                ax.set_title(f'Distribution Shift (KL={kl_div:.4f}, WD={wd:.4f})', 
                            fontsize=14, fontweight='bold')
                ax.set_xlabel('File Size (MB)')
                ax.set_ylabel('Count')
                ax.legend()
                ax.grid(alpha=0.3)
                plt.tight_layout()
                plt.savefig(plot_dir / 'distribution_shift.png', dpi=300, bbox_inches='tight')
                live.log_image(str(plot_dir / 'distribution_shift.png'))
                plt.close()
        
        print()
        
        # 2. ì„ë² ë”© ë“œë¦¬í”„íŠ¸ ë¶„ì„
        print("ğŸ”¬ Embedding Drift Analysis:")
        print("-" * 80)
        
        if baseline_emb and current_emb:
            ref_embeddings = np.array([v['embedding'] for v in baseline_emb.values() if 'embedding' in v])
            cur_embeddings = np.array([v['embedding'] for v in current_emb.values() if 'embedding' in v])
            
            if len(ref_embeddings) > 0 and len(cur_embeddings) > 0:
                # MMD ê³„ì‚°
                mmd = calculate_mmd(ref_embeddings, cur_embeddings)
                
                # Mean shift
                ref_mean = ref_embeddings.mean(axis=0)
                cur_mean = cur_embeddings.mean(axis=0)
                mean_shift = float(np.linalg.norm(ref_mean - cur_mean))
                
                # ë¶„ì‚° ë³€í™”
                ref_var = float(np.var(ref_embeddings))
                cur_var = float(np.var(cur_embeddings))
                variance_ratio = abs(cur_var - ref_var) / ref_var if ref_var > 0 else 0
                
                drift_metrics['embedding'] = {
                    'mmd': mmd,
                    'mean_shift': mean_shift,
                    'variance_change': float(variance_ratio),
                    'baseline_variance': ref_var,
                    'current_variance': cur_var
                }
                
                live.log_metric("drift/embedding/mmd", mmd)
                live.log_metric("drift/embedding/mean_shift", mean_shift)
                live.log_metric("drift/embedding/variance_change", variance_ratio)
                
                print(f"   MMD: {mmd:.4f}")
                print(f"   Mean Shift: {mean_shift:.4f}")
                print(f"   Variance Change: {variance_ratio:.1%}")
                
                # ì‹œê°í™”: PCA 3D Overlay
                from sklearn.decomposition import PCA
                from mpl_toolkits.mplot3d import Axes3D
                
                all_emb = np.vstack([ref_embeddings, cur_embeddings])
                pca = PCA(n_components=3)
                all_pca = pca.fit_transform(all_emb)
                
                ref_pca = all_pca[:len(ref_embeddings)]
                cur_pca = all_pca[len(ref_embeddings):]
                
                fig = plt.figure(figsize=(14, 10))
                ax = fig.add_subplot(111, projection='3d')
                
                # ë°ì´í„° í¬ì¸íŠ¸
                ax.scatter(ref_pca[:, 0], ref_pca[:, 1], ref_pca[:, 2],
                          alpha=0.5, s=80, label='Baseline', color='blue', 
                          edgecolors='darkblue', linewidth=0.5)
                ax.scatter(cur_pca[:, 0], cur_pca[:, 1], cur_pca[:, 2],
                          alpha=0.5, s=80, label='Current', color='red', 
                          edgecolors='darkred', linewidth=0.5)
                
                # ì¤‘ì‹¬ì 
                ref_center = ref_pca.mean(axis=0)
                cur_center = cur_pca.mean(axis=0)
                ax.scatter(*ref_center, s=400, marker='*', color='darkblue', 
                          edgecolors='black', linewidth=2, label='Baseline Center', zorder=5)
                ax.scatter(*cur_center, s=400, marker='*', color='darkred', 
                          edgecolors='black', linewidth=2, label='Current Center', zorder=5)
                
                # ì´ë™ ë²¡í„° (3D)
                if np.linalg.norm(cur_center - ref_center) > 0.1:
                    from mpl_toolkits.mplot3d.art3d import Line3D
                    line = Line3D([ref_center[0], cur_center[0]], 
                                 [ref_center[1], cur_center[1]],
                                 [ref_center[2], cur_center[2]], 
                                 color='green', linewidth=3, label='Shift Vector')
                    ax.add_line(line)
                
                ax.set_title(f'Embedding Space Drift (MMD={mmd:.4f})', 
                            fontsize=14, fontweight='bold')
                ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
                ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
                ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%})')
                ax.legend(loc='upper left')
                ax.grid(alpha=0.3)
                
                plt.tight_layout()
                plt.savefig(plot_dir / 'embedding_drift_3d.png', dpi=300, bbox_inches='tight')
                live.log_image(str(plot_dir / 'embedding_drift_3d.png'))
                plt.close()
        
        print()
        
        # 3. ì „ì²´ ë“œë¦¬í”„íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚°
        print("ğŸ¯ Overall Drift Score:")
        print("-" * 80)
        
        size_kl = drift_metrics.get('size', {}).get('kl_divergence', 0)
        emb_mmd = drift_metrics.get('embedding', {}).get('mmd', 0)
        
        # ê°€ì¤‘ í‰ê· 
        overall_score = size_kl * 0.3 + emb_mmd * 0.7
        
        drift_metrics['overall_score'] = float(overall_score)
        live.log_metric("drift/overall_score", overall_score)
        
        # ì„ê³„ê°’ ì²´í¬
        warning_threshold = params['drift']['threshold_warning']
        critical_threshold = params['drift']['threshold_critical']
        
        if overall_score > critical_threshold:
            status = 'CRITICAL'
            print(f"ğŸš¨ CRITICAL: {overall_score:.4f} > {critical_threshold}")
        elif overall_score > warning_threshold:
            status = 'WARNING'
            print(f"âš ï¸  WARNING: {overall_score:.4f} > {warning_threshold}")
        else:
            status = 'NORMAL'
            print(f"âœ… NORMAL: {overall_score:.4f}")
        
        drift_metrics['status'] = status
        drift_metrics['timestamp'] = timestamp
        live.log_param("drift_status", status)
        
        # ë“œë¦¬í”„íŠ¸ ìŠ¤ì½”ì–´ ë°” ì°¨íŠ¸
        import matplotlib.pyplot as plt
        
        metrics_to_plot = {
            'Size KL': size_kl,
            'Embedding MMD': emb_mmd,
            'Overall': overall_score
        }
        
        fig, ax = plt.subplots(figsize=(10, 5))
        colors = ['blue', 'purple', 'red' if overall_score > critical_threshold 
                 else 'orange' if overall_score > warning_threshold else 'green']
        bars = ax.bar(metrics_to_plot.keys(), metrics_to_plot.values(), 
                     color=colors, alpha=0.7, edgecolor='black')
        
        ax.axhline(warning_threshold, color='orange', linestyle='--', 
                  linewidth=2, label=f'Warning ({warning_threshold})')
        ax.axhline(critical_threshold, color='red', linestyle='--', 
                  linewidth=2, label=f'Critical ({critical_threshold})')
        
        # ê°’ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        ax.set_title(f'Drift Metrics - {status}', fontsize=14, fontweight='bold')
        ax.set_ylabel('Drift Score')
        ax.legend()
        ax.grid(alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig(plot_dir / 'drift_scores.png', dpi=300, bbox_inches='tight')
        live.log_image(str(plot_dir / 'drift_scores.png'))
        plt.close()
        
        # ê²°ê³¼ ì €ì¥
        with open(drift_dir / 'metrics.json', 'w') as f:
            json.dump(drift_metrics, f, indent=2)
        
        # ë“œë¦¬í”„íŠ¸ íƒ€ì„ë¼ì¸ ì—…ë°ì´íŠ¸ (TSV for DVC plots)
        timeline_file = Path("analysis/drift/timeline.tsv")
        
        # ê¸°ì¡´ íƒ€ì„ë¼ì¸ ë¡œë“œ ë˜ëŠ” ìƒì„±
        if timeline_file.exists():
            with open(timeline_file, 'r') as f:
                lines = f.readlines()
        else:
            lines = ['timestamp\toverall_score\tstatus\tfiles_added\tfiles_removed\n']
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        lines.append(f"{timestamp}\t{overall_score:.4f}\t{status}\t{len(added)}\t{len(removed)}\n")
        
        with open(timeline_file, 'w') as f:
            f.writelines(lines)
        
        print()
        print("=" * 80)
        print(f"âœ… ë“œë¦¬í”„íŠ¸ íƒì§€ ì™„ë£Œ: {status}")
        print(f"   Overall Score: {overall_score:.4f}")
        print(f"   íŒŒì¼ ë³€ê²½: +{len(added)} -{len(removed)}")

if __name__ == "__main__":
    detect_drift()
